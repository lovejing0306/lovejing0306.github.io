---
layout: post
title: 训练集、验证集、测试集
categories: [MachineLearning]
description: 训练集、验证集、测试集
keywords: MachineLearning
---


训练集、验证集、测试集
---


## 训练集
训练集用于训练模型，理论上训练集越大越好。

## 验证集
&emsp;&emsp;大多数机器学习算法具有超参数，超参数的值无法通过学习算法拟合出来（比如正则化项的系数、控制模型容量的参数 ）。为了解决这个问题，可以引入验证集。将训练数据分成两个不相交的子集：训练集用于学习模型，验证集用于选择超参数。

&emsp;&emsp;通常要求验证集足够大。如果验证集很小，那么模型的超参数可能就记住了一个小验证集里的样本，模型将对验证集严重过拟合。验证集通常会低估泛化误差。因此当超参数优化完成后，需要通过测试集来估计泛化误差。

## 测试集
&emsp;&emsp;测试集用于评估模型的泛化误差。理论上测试集越大，则模型的泛化误差评估的越准确。测试集中一定不能含有训练集中的样本。如果将训练样本放入测试集中，则会低估泛化误差。

测试集 vs 验证集：
1. 测试集通常用于对模型的预测能力进行评估，它提供了模型预测能力的无偏估计。如果不需要对模型预测能力的无偏估计，则不需要测试集。
2. 验证集用于超参数的选择，它无法提供模型预测能力的有偏估计。因为模型依赖于超参数，而超参数依赖于验证集。因此验证集参与了模型的构建，这意味着模型已经考虑了验证集的信息。
        

## 拆分
### 小批量数据
1. 如果未设置验证集，则将数据三七分： $0.7$ 的数据用作训练集、 $0.3$ 的数据用作测试集。
2. 如果设置验证集，则将数据划分为： $0.6$ 的数据用作训练集、 $0.2$ 的数据用过验证集、 $0.20$ 的数据用作测试集。

### 大批量数据
1. 对于百万级别的数据，其中 $1$ 万条作为验证集、 $1$ 万条作为测试集即可。
2. 验证集的目的就是验证不同的超参数；测试集的目的就是比较不同的模型。一方面它们要足够大，才足够评估超参数、模型；另一方面，如果它们太大，则会浪费数据（验证集和训练集的数据无法用于训练）。

### k 折交叉验证
先将所有数据拆分成 $k$ 份，然后其中 $1$  份作为测试集，其他 $k-1$  份作为训练集。这里并没有验证集来做超参数的选择。所有测试集的测试误差的均值作为模型的预测能力的一个估计。

使用 $k$ 折交叉的原因是：样本集太小。如果选择一部分数据来训练，则有两个问题：
1. 训练数据的分布可能与真实的分布有偏离。 $k$ 折交叉让所有的数据参与训练，会使得这种偏离得到一定程度的修正。
2. 训练数据太少，容易陷入过拟合。 $k$ 折交叉让所有数据参与训练，会一定程度上缓解过拟合。

## 分布不匹配
&emsp;&emsp;深度学习时代，经常会发生：训练集和验证集、测试集的数据分布不同。如：训练集的数据可能是从网上下载的高清图片，测试集的数据可能是用户上传的、低像素的手机照片。
1. 必须保证验证集、测试集的分布一致，它们都要很好的代表你的真实应用场景中的数据分布。
2. 训练数据可以与真实应用场景中的数据分布不一致，因为最终关心的是在模型真实应用场景中的表现。

如果发生了数据分布不匹配问题，则可以想办法让训练集的分布更接近验证集。
1. 一种做法是：收集更多的、分布接近验证集的数据作为训练集合。
2. 另一种做法是：人工合成训练数据，使得它更接近验证集。该策略有一个潜在问题：你可能只是模拟了全部数据空间中的一小部分。导致你的模型对这一小部分过拟合。

当训练集和验证集、测试集的数据分布不同时，有以下经验原则：
1. 确保验证集和测试集的数据来自同一分布。因为需要使用验证集来优化超参数，而优化的最终目标是希望模型在测试集上表现更好。
2. 确保验证集和测试集能够反映未来得到的数据，或者最关注的数据。
3. 确保数据被随机分配到验证集和测试集上。

当训练集和验证集、测试集的数据分布不同时，分析偏差和方差的方式有所不同。
1. 如果训练集和验证集的分布一致，那么当训练误差和验证误差相差较大时，我们认为存在很大的方差问题。
2. 如果训练集和验证集的分布不一致，那么当训练误差和验证误差相差较大时，有两种原因：
   1. 第一个原因：模型只见过训练集数据，没有见过验证集的数据导致的，是数据不匹配的问题。
   2. 第二个原因：模型本来就存在较大的方差。
   
   为了弄清楚原因，需要将训练集再随机划分为：训练-训练集、训练-验证集。这时候，训练-训练集、训练-验证集是同一分布的。
   1. 模型在训练-训练集和训练-验证集上的误差的差距代表了模型的方差。
   2. 模型在训练-验证集和验证集上的误差的差距代表了数据不匹配问题的程度。
