---
layout: post
title: 偏差方差
categories: [MachineLearning]
description: 偏差方差
keywords: MachineLearning
---


偏差方差
---


## 偏差方差分解
&emsp;&emsp;泛化误差可分解为偏差、方差与噪声的和，其公式如下：

$$
E\left( f;D \right) ={ bias }^{ 2 }\left( x \right) +var\left( x \right) +{ \varepsilon  }^{ 2 }
$$

偏差(bias)：描述的是预测值的期望与真实值之间的差距。偏差越大，越偏离真实数据。

方差(variance)：描述的是预测值的变化范围，离散程度。方差越大，数据的分布越分散，对原始数据的拟合程度越大。

噪声：刻画了学习任务本身的难易程度。可以想象成在坑洼路面开车时不好的路面。

&emsp;&emsp;偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难易程度所共同决定的。

&emsp;&emsp;给定一个学习任务，为了取得较好的泛化性能，则需使偏差较小且方差较小。一般来说，偏差与方差是有冲突的，称为偏差-方差窘境（bias-variance dilemma），如下图所示：

<center>
    <img 
    src="https://github.com/lovejing0306/Images/blob/master/MachineLearning/evaluation/bias_var.png?raw=true"
    width="512" height=""
    >
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"> BV </div>
</center>

1. 在训练不足时，模型的拟合能力不够强，训练数据的扰动不足以使模型产生显著变化，此时偏差主导了泛化误差。
2. 随着训练程度的加深，模型的拟合能力逐渐增强，训练数据发生的扰动逐渐被模型学习到，方差逐渐主导了泛化误差。
3. 在训练充分后，模型的拟合能力非常强，训练数据发生的轻微扰动都会导致模型发生显著变化。若训练数据自身的、非全局的特性被模型学到了，则将发生过拟合。

## 误差诊断
通常偏差方差反映了模型的过拟合与欠拟合。
1. 高偏差对应于模型的欠拟合：模型过于简单，以至于未能很好的学习训练集，从而使得训练误差过高。此时模型预测的方差较小，表示预测较稳定。但是模型预测的偏差会较大，表示预测不准确。
2. 高方差对应于模型的过拟合：模型过于复杂，以至于将训练集的细节都学到，将训练集的一些细节当做普遍的规律，从而使得测试集误差与训练集误差相距甚远。此时模型预测的偏差较小，表示预测较准确。但是模型预测的方差较大，表示预测较不稳定。

误差诊断：通过训练误差和测试误差来分析模型是否存在高方差、高偏差。
1. 如果训练误差较高：说明模型的偏差较大，模型出现了欠拟合。
2. 如果训练误差较低，而测试误差较高：说明模型的方差较大，出现了过拟合。
3. 如果训练误差较低，测试误差也较低：说明模型的方差和偏差都适中，是一个比较理想的模型。
4. 如果训练误差较高，且测试误差更高：说明模型的方差和偏差都较大。

上述分析的前提是：训练集、测试集的数据来自于同一个分布，且最优误差较小。否则讨论更复杂。

## 误差缓解
&emsp;&emsp;高方差和高偏差是两种不同的情况。如果算法存在高偏差的问题，则准备更多训练数据其实没什么卵用。所以首先要清楚：问题是高偏差还是高方差还是二者兼有。

如果模型存在高偏差，则通过以下策略可以缓解：
1. 选择一个容量更大、更复杂的模型。
2. 使用更先进的最优化算法。该策略通常在神经网络中使用。

如果模型存在高方差，则通过以下策略可以缓解：
1. 增加更多的训练数据。它通过更多的训练样本来对模型参数增加约束，会降低模型容量。如果有更多的训练数据，则一定会降低方差。
2. 使用正则化。它通过正则化项来对模型参数增加约束，也会降低模型容量。有时候更多的训练数据难以获取，只能使用正则化策略。

&emsp;&emsp;通常优先解决高偏差的问题。这是最低标准，要反复尝试，直到训练误差降低到足够小。然后试图降低方差。总之就是不断重复尝试，直到找到一个低偏差、低方差的模型。
